{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from kerastuner import tuners\n",
    "from kerastuner import HyperParameters\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import captchanet\n",
    "\n",
    "data_dir = Path('/home/hadim/.data/Neural_Network/captchanet')\n",
    "dataset_dir = data_dir / 'dataset_v6'\n",
    "\n",
    "train_data_dir = dataset_dir / 'training'\n",
    "val_data_dir = dataset_dir / 'validation'\n",
    "\n",
    "tokenizer_path = dataset_dir / \"tokenizer.json\"\n",
    "\n",
    "log_dir = data_dir / 'log'\n",
    "log_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "model_dir = data_dir / 'model'\n",
    "model_dir.mkdir(exist_ok=True, parents=True)\n",
    "  \n",
    "# Get tokenizer\n",
    "with open(tokenizer_path) as f:\n",
    "  #tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(f.read())\n",
    "  from keras_preprocessing import text\n",
    "  tokenizer = text.tokenizer_from_json(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0714 17:16:44.471898 140026231895872 deprecation.py:323] From /home/hadim/local/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/ops/image_ops_impl.py:1511: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "# Build the dataset\n",
    "def make_dataset(data_dir, tokenizer, batch_size, image_size=None, shuffle=False, n=None):\n",
    "\n",
    "  fnames = [str(p) for p in data_dir.glob(\"*.tfrecord\")]\n",
    "  dataset = tf.data.TFRecordDataset(fnames)\n",
    "  if n:\n",
    "    dataset = dataset.take(n)\n",
    "  if shuffle:\n",
    "      dataset = dataset.shuffle(buffer_size=2048)\n",
    "      \n",
    "  # We could infer it from the dataset but here it's hard-coded.\n",
    "  max_len_word = 10\n",
    "      \n",
    "  decode_fn = captchanet.decode_data(tokenizer, max_len_word, image_size=image_size)\n",
    "  dataset = dataset.map(map_func=decode_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "  \n",
    "  dataset = dataset.batch(batch_size)\n",
    "  dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "  return dataset\n",
    "\n",
    "batch_size = 12\n",
    "image_size = (299, 299)\n",
    "train_dataset = make_dataset(train_data_dir, tokenizer, batch_size=batch_size, image_size=image_size, shuffle=True, n=200)\n",
    "val_dataset = make_dataset(val_data_dir, tokenizer, batch_size=batch_size, image_size=image_size, shuffle=False, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(image_shape, image_type, vocabulary_size, max_len_word, params=None, do_fine_tuning=False, do_build=True):\n",
    "\n",
    "  def _builder(hp):\n",
    "\n",
    "    dropout_rate = hp.Choice('dropout_rate', values=[0.1, 0.2, 0.3, 0.4, 0.5], default=0.2)\n",
    "    use_regularizer = hp.Choice('use_regularizer', values=[True, False], default=True)\n",
    "    regularizer_value = hp.Choice('regularizer_value', values=[1e-1, 1e-2, 1e-3, 1e-4, 1e-5], default=1e-4)\n",
    "    optimizer_name = hp.Choice('optimizer_name', values=['sgd', 'adam', 'rmsprop'], default='sgd')\n",
    "    starting_lr = hp.Choice('starting_lr', values=[1e-1, 1e-2, 1e-3], default=1e-3)\n",
    "    momentum = hp.Choice('momentum', values=[0.9, 0.95, 0.99], default=0.9)\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    #module_selection = (\"mobilenet_v2\", 224, 1280)\n",
    "    module_selection = (\"inception_v3\", 299, 2048)\n",
    "\n",
    "    handle_base, pixels, feature_size = module_selection\n",
    "    module_handle = f\"https://tfhub.dev/google/tf2-preview/{handle_base}/feature_vector/4\"\n",
    "    model_image_shape = (pixels, pixels, 3)\n",
    "\n",
    "    inputs = tf.keras.layers.Input(name='image', shape=model_image_shape, dtype=image_type)\n",
    "    x = inputs\n",
    "\n",
    "    x = hub.KerasLayer(module_handle, output_shape=[feature_size], trainable=do_fine_tuning)(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    padding_vocabulary_size = vocabulary_size + 1\n",
    "    outputs = []\n",
    "    for i in range(max_len_word):\n",
    "      if use_regularizer:\n",
    "        regularizer = tf.keras.regularizers.l2(regularizer_value)\n",
    "      else:\n",
    "        regularizer = None\n",
    "      out = tf.keras.layers.Dense(padding_vocabulary_size, kernel_regularizer=regularizer, activation='softmax', name=f'character_{i}')(x)\n",
    "      outputs.append(out)\n",
    "    outputs = tf.keras.layers.Concatenate()(outputs)\n",
    "    outputs = tf.keras.layers.Reshape((max_len_word, padding_vocabulary_size))(outputs)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    # Optimizer Parameters\n",
    "    sgd_params = {}\n",
    "    sgd_params['learning_rate'] = starting_lr\n",
    "    sgd_params['momentum'] = momentum\n",
    "    sgd_params['nesterov'] = True\n",
    "\n",
    "    adam_params = {}\n",
    "    adam_params['learning_rate'] = starting_lr\n",
    "    adam_params['amsgrad'] = True\n",
    "\n",
    "    rmsprop_params = {}\n",
    "    rmsprop_params['learning_rate'] = starting_lr\n",
    "\n",
    "    # Build optimizer.\n",
    "    if optimizer_name == 'sgd':\n",
    "      optimizer = tf.keras.optimizers.SGD(**sgd_params)\n",
    "    elif optimizer_name == 'adam':\n",
    "      optimizer = tf.keras.optimizers.Adam(**adam_params)\n",
    "    elif optimizer_name == 'rmsprop':\n",
    "      optimizer = tf.keras.optimizers.RMSprop(**rmsprop_params)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "  hp = HyperParameters()\n",
    "\n",
    "  if params:\n",
    "    for key, value in params.items():\n",
    "      hp.Fixed(key, value)\n",
    "      \n",
    "  if not do_build:\n",
    "    return _builder\n",
    "\n",
    "  return _builder(hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = []\n",
    "\n",
    "log_path = log_dir / datetime.datetime.now().strftime(\"%Y.%m.%d-%H.%M.%S\")\n",
    "log_path.mkdir(exist_ok=True)\n",
    "\n",
    "tb = captchanet.LRTensorBoard(log_dir=str(log_path), write_images=False, write_graph=True)\n",
    "#callbacks.append(tb)\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=5)\n",
    "callbacks.append(reduce_lr)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=1e-3, patience=10)\n",
    "#callbacks.append(early_stop)\n",
    "\n",
    "tqdm_progress = captchanet.TQDMCallback()\n",
    "callbacks.append(tqdm_progress)\n",
    "\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(str(log_path / 'log.csv'))\n",
    "callbacks.append(csv_logger)\n",
    "\n",
    "# Get image shape\n",
    "image, label = [d for d in train_dataset.take(1)][0]\n",
    "image_shape = image.shape[1:]\n",
    "image_type = image.dtype\n",
    "\n",
    "do_fine_tuning = True\n",
    "\n",
    "params = {}\n",
    "params['dropout_rate'] = 0.4\n",
    "params['use_regularizer'] = True\n",
    "params['regularizer_value'] = 1e-5\n",
    "params['optimizer_name'] = 'adam'\n",
    "params['starting_lr'] = 1e-2\n",
    "params['momentum'] = 0.95\n",
    "\n",
    "# Build the model.\n",
    "vocabulary_size = len(tokenizer.index_word)\n",
    "model = build_model(image_shape, image_type, vocabulary_size, max_len_word=10, params=params, do_fine_tuning=do_fine_tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace6c6c989764daea458828a1d1eedf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=200, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcbf3394ce9b445ca858138637bfb533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Epoch: 0', max=1, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0714 17:18:42.205410 140026231895872 deprecation.py:323] From /home/hadim/local/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c5b1c941bb444e89d27be4f54580e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch: 1', max=17, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c51f43c7ddd4919865fa21a9bac4651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch: 2', max=17, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6bd5a4b3394bf28140ff285339a100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch: 3', max=17, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d892e7ee3df400c831ef83852c1cf8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch: 4', max=17, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d561d0ad8724068abfb4b14b594fe20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch: 5', max=17, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15344872c04f46bd934bcea2691ad487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch: 6', max=17, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976e73600a144c4f94a211ef40c94b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch: 7', max=17, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5035c96d8948fe8d3a896528b89f75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch: 8', max=17, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1bd17a6d8d4c0aa6bb38ae6c0bcb31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch: 9', max=17, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e96e60683f244b6e90d1a1ab246a41d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch: 10', max=17, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-72e0b95c873c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/local/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/local/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/local/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3517\u001b[0m     \u001b[0;31m# (otherwise it's just a no-op.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3518\u001b[0m     return nest.pack_sequence_as(\n\u001b[0;32m-> 3519\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cpu_nograd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3520\u001b[0m         expand_composites=True)\n\u001b[1;32m   3521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3517\u001b[0m     \u001b[0;31m# (otherwise it's just a no-op.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3518\u001b[0m     return nest.pack_sequence_as(\n\u001b[0;32m-> 3519\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cpu_nograd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3520\u001b[0m         expand_composites=True)\n\u001b[1;32m   3521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_cpu_nograd\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    950\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mCPU\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0mbacked\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mcontents\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \"\"\"\n\u001b[0;32m--> 952\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_nograd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CPU:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_copy_nograd\u001b[0;34m(self, ctx, device_name)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m       \u001b[0mnew_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "model.fit(train_dataset, validation_data=val_dataset, epochs=n_epochs, callbacks=callbacks, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_path = model_dir / 'v7'\n",
    "model_path.mkdir(exist_ok=True)\n",
    "model.save(str(model_path / 'model'))\n",
    "\n",
    "# Save tokenizer\n",
    "with open(model_path / tokenizer_path.name, 'w') as f:\n",
    "  f.write(tokenizer.to_json())\n",
    "\n",
    "# Save history\n",
    "history = pd.DataFrame(model.history.history)\n",
    "history_path = model_path / 'history.csv'\n",
    "history.to_csv(str(history_path), index=False)\n",
    "\n",
    "# Pack and zip the model directory\n",
    "import shutil\n",
    "archive_path = model_dir / model_path.stem\n",
    "shutil.rmtree(model_path / '.ipynb_checkpoints', ignore_errors=True)\n",
    "shutil.make_archive(archive_path, 'zip', root_dir=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check history\n",
    "history = pd.read_csv(history_path)\n",
    "\n",
    "n = 3\n",
    "size = 3.5\n",
    "ncols = 3\n",
    "w_h_scale = 2\n",
    "figsize = (ncols * size * w_h_scale, size)\n",
    "fig, axs = plt.subplots(nrows=n//ncols, ncols=ncols, figsize=figsize)\n",
    "axs = axs.flatten()\n",
    "\n",
    "axs[0].plot(history['val_accuracy'], label='val_accuracy')\n",
    "axs[0].plot(history['accuracy'], label='accuracy')\n",
    "axs[0].set_xlabel('epoch')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(history['val_loss'], label='val_loss')\n",
    "axs[1].plot(history['loss'], label='loss')\n",
    "axs[1].set_xlabel('epoch')\n",
    "axs[1].legend()\n",
    "\n",
    "axs[2].plot(history['lr'])\n",
    "axs[2].set_xlabel('epoch')\n",
    "\n",
    "fig.savefig(model_path / 'history.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = model\n",
    "\n",
    "# Perform prediction\n",
    "model_image_size = (299, 299)\n",
    "n  = 8\n",
    "fnames = [str(p) for p in val_data_dir.glob(\"*.tfrecord\")]\n",
    "dataset = tf.data.TFRecordDataset(fnames)\n",
    "dataset = dataset.map(map_func=captchanet.decode_data(tokenizer, max_len_word=10, image_size=model_image_size, input_as_dict=True))\n",
    "dataset = dataset.shuffle(1024)\n",
    "dataset = dataset.batch(n)\n",
    "data = [d for d in dataset.take(1)][0]\n",
    "\n",
    "images = data['image']\n",
    "labels = data['label']\n",
    "\n",
    "labels = loaded_model(images)\n",
    "\n",
    "# Decode\n",
    "labels = labels.numpy().argmax(axis=2)\n",
    "predicted_words = [tokenizer.sequences_to_texts([label])[0] for label in labels]\n",
    "predicted_words = [word.replace(' ', '') for word in predicted_words]\n",
    "\n",
    "# Plot\n",
    "original_images = data['original_image'].numpy()\n",
    "words = data['word'].numpy()\n",
    "words = [w.decode('utf-8').replace('0', '') for w in words]\n",
    "\n",
    "size = 2\n",
    "ncols = 2\n",
    "nrows = n // ncols\n",
    "ratio = original_images.shape[2] / original_images.shape[1]\n",
    "figsize = (ncols * size * ratio, size * nrows)\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize, constrained_layout=True)\n",
    "axs = axs.flatten()\n",
    "\n",
    "for image, word, predicted_word, ax in zip(original_images, words, predicted_words, axs):\n",
    "  ax.imshow(image)\n",
    "  \n",
    "  mark = 'OK' if predicted_word == word else 'WRONG'\n",
    "  text = f'True: {word} ({len(word)})'\n",
    "  text += f' - Predicted: {predicted_word} ({len(predicted_word)})'\n",
    "  text += f\" - {mark}\"\n",
    "  ax.set_title(text, fontsize=14)\n",
    "  \n",
    "fig.savefig(model_path / 'example_prediction.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:captchanet]",
   "language": "python",
   "name": "conda-env-captchanet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
