{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOT WORKING YET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import captchanet\n",
    "\n",
    "data_dir = Path('/home/hadim/.data/Neural_Network/captchanet')\n",
    "\n",
    "dataset_dir = data_dir / 'dataset_v6'\n",
    "train_data_dir = dataset_dir / 'training'\n",
    "val_data_dir = dataset_dir / 'validation'\n",
    "\n",
    "model_dir = data_dir / 'model'\n",
    "model_name = 'v6'\n",
    "model_path = model_dir / model_name\n",
    "\n",
    "tokenizer_path = model_path / \"tokenizer.json\"\n",
    "\n",
    "# Get tokenizer\n",
    "with open(tokenizer_path) as f:\n",
    "  #tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(f.read())\n",
    "  from keras_preprocessing import text\n",
    "  tokenizer = text.tokenizer_from_json(f.read())\n",
    "  \n",
    "model = tf.keras.models.load_model(str(model_path / 'model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0713 19:23:19.385547 139967693227840 deprecation.py:323] From /home/hadim/local/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/ops/image_ops_impl.py:1511: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "model_image_size = (224, 224)\n",
    "n  = 2\n",
    "fnames = [str(p) for p in val_data_dir.glob(\"*.tfrecord\")]\n",
    "dataset = tf.data.TFRecordDataset(fnames)\n",
    "dataset = dataset.map(map_func=captchanet.decode_data(tokenizer, image_size=model_image_size, max_len_word=10, input_as_dict=True))\n",
    "dataset = dataset.shuffle(1024)\n",
    "dataset = dataset.batch(n)\n",
    "data = [d for d in dataset.take(1)][0]\n",
    "\n",
    "images = data['image']\n",
    "labels = data['label']\n",
    "labels = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0713 19:29:39.462048 139967693227840 saved_model.py:758] Skipping full serialization of Keras model <__main__.CaptchaSolverInferenceModel object at 0x7f4b37e6ccf8>, because its inputs are not defined.\n"
     ]
    }
   ],
   "source": [
    "# Define a model that do image preprocessing before inference.\n",
    "class CaptchaSolverInferenceModel(tf.keras.Model):\n",
    "  \n",
    "  def __init__(self, captchanet_model, **kwargs):\n",
    "    super().__init__(**kwargs)\n",
    "    self.captchanet_model = captchanet_model\n",
    "\n",
    "  @tf.function(input_signature=[tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.uint8)])\n",
    "  def solve(self, images):\n",
    "    images = tf.cast(images, tf.float32)\n",
    "    \n",
    "    # Normalize images\n",
    "    #images = tf.image.per_image_standardization(images)\n",
    "    #stddev = tf.math.reduce_std(images, axis=0)\n",
    "    #mean = tf.math.reduce_mean(images, axis=0)\n",
    "    #images = (images - mean) / stddev\n",
    "    \n",
    "    images = tf.image.resize(images, (224, 224))\n",
    "    \n",
    "    labels = model(images)\n",
    "    #labels = tf.argmax(labels, axis=2)\n",
    "    # TODO: find a way to integrate the tokenizer.\n",
    "    \n",
    "    # Freeze the tokenizer\n",
    "    #n_letter = max(tokenizer.index_word.keys()) + 1\n",
    "    #index = [''] * n_letter\n",
    "    #for k, v in tokenizer.index_word.items():\n",
    "    #  index[k] = v\n",
    "    #index = tf.constant(index, dtype=tf.string)\n",
    "        \n",
    "    # Decode labels\n",
    "    #decoder = lambda x: tf.gather_nd(index, tf.expand_dims(x, axis=-1))\n",
    "    #words = tf.map_fn(decoder, labels, dtype=tf.string)\n",
    "    #joiner = lambda x: tf.strings.reduce_join(x, axis=0)\n",
    "    #words = tf.map_fn(joiner, words, dtype=tf.string)\n",
    "\n",
    "    return images\n",
    "\n",
    "model = tf.saved_model.load(str(model_path / 'model'))\n",
    "inference_model = CaptchaSolverInferenceModel(model)\n",
    "inference_model_path = model_path.parent / 'test_model_tfjs'\n",
    "tf.saved_model.save(inference_model, str(inference_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of node Func/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/keras_layer/StatefulPartitionedCall/StatefulPartitionedCall_1/input/_2007 was passed float from Func/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/keras_layer/StatefulPartitionedCall/input/_1139:0 incompatible with expected resource.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/local/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/framework/importer.py\u001b[0m in \u001b[0;36mimport_graph_def\u001b[0;34m(graph_def, input_map, return_elements, name, op_dict, producer_op_list)\u001b[0m\n\u001b[1;32m    426\u001b[0m         results = c_api.TF_GraphImportGraphDefWithResults(\n\u001b[0;32m--> 427\u001b[0;31m             graph._c_graph, serialized, options)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScopedTFImportGraphDefResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input 0 of node Func/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/keras_layer/StatefulPartitionedCall/StatefulPartitionedCall_1/input/_2007 was passed float from Func/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/keras_layer/StatefulPartitionedCall/input/_1139:0 incompatible with expected resource.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-034eae55d978>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflowjs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfjs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtfjs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tf_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/home/hadim/testmodel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/local/conda/envs/captchanet/lib/python3.7/site-packages/tensorflowjs/converters/tf_saved_model_conversion_v2.py\u001b[0m in \u001b[0;36mconvert_tf_saved_model\u001b[0;34m(saved_model_dir, output_dir, signature_def, saved_model_tags, quantization_dtype, skip_op_check, strip_debug_ops)\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0mconcrete_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignature_def\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m   frozen_func = convert_to_constants.convert_variables_to_constants_v2(\n\u001b[0;32m--> 287\u001b[0;31m       concrete_func)\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m   optimize_graph(frozen_func, output_graph, model.tensorflow_version,\n",
      "\u001b[0;32m~/local/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/framework/convert_to_constants.py\u001b[0m in \u001b[0;36mconvert_variables_to_constants_v2\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    250\u001b[0m   new_func = wrap_function.function_from_graph_def(output_graph_def,\n\u001b[1;32m    251\u001b[0m                                                    \u001b[0mnew_input_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m                                                    new_output_names)\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m   \u001b[0;31m# Manually propagate shape for input tensors where the shape is not correctly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/eager/wrap_function.py\u001b[0m in \u001b[0;36mfunction_from_graph_def\u001b[0;34m(graph_def, inputs, outputs)\u001b[0m\n\u001b[1;32m    605\u001b[0m     \u001b[0mimporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m   \u001b[0mwrapped_import\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_imports_graph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m   \u001b[0mimport_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped_import\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m   return wrapped_import.prune(\n",
      "\u001b[0;32m~/local/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/eager/wrap_function.py\u001b[0m in \u001b[0;36mwrap_function\u001b[0;34m(fn, signature, name)\u001b[0m\n\u001b[1;32m    583\u001b[0m           \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m           \u001b[0madd_control_dependencies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m           collections={}),\n\u001b[0m\u001b[1;32m    586\u001b[0m       \u001b[0mvariable_holder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mholder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m       signature=signature)\n",
      "\u001b[0;32m~/local/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    714\u001b[0m                                           converted_func)\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/eager/wrap_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_with_variable_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_variable_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/eager/wrap_function.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_creator_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/eager/wrap_function.py\u001b[0m in \u001b[0;36m_imports_graph_def\u001b[0;34m()\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_imports_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mimporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m   \u001b[0mwrapped_import\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_imports_graph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/local/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/framework/importer.py\u001b[0m in \u001b[0;36mimport_graph_def\u001b[0;34m(graph_def, input_map, return_elements, name, op_dict, producer_op_list)\u001b[0m\n\u001b[1;32m    429\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;31m# Create _DefinedFunctions for any imported functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of node Func/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/keras_layer/StatefulPartitionedCall/StatefulPartitionedCall_1/input/_2007 was passed float from Func/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/keras_layer/StatefulPartitionedCall/input/_1139:0 incompatible with expected resource."
     ]
    }
   ],
   "source": [
    "import tensorflowjs as tfjs\n",
    "tfjs.converters.convert_tf_saved_model(str(inference_model_path), '/home/hadim/testmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=199896, shape=(2, 10, 60), dtype=float32, numpy=\n",
       "array([[[2.9817571e-07, 3.5087726e-04, 3.0216272e-05, ...,\n",
       "         3.7906871e-06, 6.3952053e-04, 6.7858683e-04],\n",
       "        [7.6777829e-09, 5.2266045e-05, 6.4965086e-08, ...,\n",
       "         3.6354169e-05, 3.2530249e-07, 6.5024155e-06],\n",
       "        [1.5669572e-06, 6.3543380e-03, 8.5173924e-05, ...,\n",
       "         4.7941823e-05, 1.5778298e-03, 3.6667331e-04],\n",
       "        ...,\n",
       "        [9.9802303e-01, 4.3144079e-05, 2.9469247e-05, ...,\n",
       "         2.3697708e-05, 6.6060158e-05, 6.6571702e-06],\n",
       "        [9.9970835e-01, 1.2790371e-05, 1.8501147e-06, ...,\n",
       "         3.0394544e-06, 8.0580976e-06, 7.0386136e-06],\n",
       "        [9.9997234e-01, 3.8388180e-07, 4.0560349e-07, ...,\n",
       "         2.2472686e-07, 3.0780257e-06, 1.2501309e-06]],\n",
       "\n",
       "       [[5.1425661e-05, 1.7609533e-02, 3.8806025e-03, ...,\n",
       "         1.3713936e-03, 9.5771207e-04, 1.6140189e-03],\n",
       "        [1.9176459e-06, 5.2574975e-05, 1.7011825e-04, ...,\n",
       "         2.0871112e-04, 1.6116243e-04, 3.8373042e-03],\n",
       "        [4.9904429e-07, 7.1186041e-06, 1.7969931e-05, ...,\n",
       "         4.0761159e-05, 1.4916497e-04, 9.1249443e-05],\n",
       "        ...,\n",
       "        [2.1077717e-04, 2.3631838e-03, 1.8866742e-02, ...,\n",
       "         1.0826561e-03, 6.3171256e-01, 2.9102415e-02],\n",
       "        [3.6165770e-06, 1.1174552e-03, 3.7318320e-04, ...,\n",
       "         1.8048894e-03, 1.2679131e-03, 6.7967838e-03],\n",
       "        [4.9329734e-01, 1.2064061e-02, 5.5674065e-02, ...,\n",
       "         6.8599032e-03, 4.6578064e-03, 2.9727202e-03]]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:captchanet]",
   "language": "python",
   "name": "conda-env-captchanet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
