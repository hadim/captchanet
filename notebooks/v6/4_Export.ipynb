{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import captchanet\n",
    "\n",
    "data_dir = Path('/home/hadim/.data/Neural_Network/captchanet')\n",
    "\n",
    "dataset_dir = data_dir / 'dataset_v6'\n",
    "train_data_dir = dataset_dir / 'training'\n",
    "val_data_dir = dataset_dir / 'validation'\n",
    "\n",
    "model_dir = data_dir / 'model'\n",
    "model_name = 'v6'\n",
    "model_path = model_dir / model_name\n",
    "\n",
    "tokenizer_path = model_path / \"tokenizer.json\"\n",
    "\n",
    "# Get tokenizer\n",
    "with open(tokenizer_path) as f:\n",
    "  #tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(f.read())\n",
    "  from keras_preprocessing import text\n",
    "  tokenizer = text.tokenizer_from_json(f.read())\n",
    "  \n",
    "model = tf.keras.models.load_model(str(model_path / 'model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0714 00:36:05.113139 139779263436608 saved_model.py:758] Skipping full serialization of Keras model <__main__.CaptchaSolverInferenceModel object at 0x7f1b2615f668>, because its inputs are not defined.\n",
      "W0714 00:36:05.645812 139779263436608 deprecation.py:323] From /home/hadim/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/ops/image_ops_impl.py:1511: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "W0714 00:36:06.461832 139779263436608 saved_model.py:765] Skipping full serialization of Keras layer <tensorflow.python.keras.saving.saved_model.InputLayer object at 0x7f1efb146588>, because it is not built.\n",
      "W0714 00:36:06.463783 139779263436608 saved_model.py:765] Skipping full serialization of Keras layer <tensorflow.python.keras.saving.saved_model.KerasLayer object at 0x7f1efb146668>, because it is not built.\n",
      "W0714 00:36:06.466694 139779263436608 saved_model.py:765] Skipping full serialization of Keras layer <tensorflow.python.keras.saving.saved_model.Dropout object at 0x7f1efb146978>, because it is not built.\n",
      "W0714 00:36:06.468388 139779263436608 saved_model.py:765] Skipping full serialization of Keras layer <tensorflow.python.keras.saving.saved_model.Dense object at 0x7f1efb146da0>, because it is not built.\n",
      "W0714 00:36:06.470132 139779263436608 saved_model.py:765] Skipping full serialization of Keras layer <tensorflow.python.keras.saving.saved_model.Dense object at 0x7f1efb1504e0>, because it is not built.\n",
      "W0714 00:36:06.471901 139779263436608 saved_model.py:765] Skipping full serialization of Keras layer <tensorflow.python.keras.saving.saved_model.Dense object at 0x7f1efb1502b0>, because it is not built.\n",
      "W0714 00:36:06.473606 139779263436608 saved_model.py:765] Skipping full serialization of Keras layer <tensorflow.python.keras.saving.saved_model.Dense object at 0x7f1efb150b00>, because it is not built.\n",
      "W0714 00:36:06.474956 139779263436608 saved_model.py:765] Skipping full serialization of Keras layer <tensorflow.python.keras.saving.saved_model.Dense object at 0x7f1efb150e48>, because it is not built.\n",
      "W0714 00:36:06.476653 139779263436608 saved_model.py:765] Skipping full serialization of Keras layer <tensorflow.python.keras.saving.saved_model.Dense object at 0x7f1efb16b1d0>, because it is not built.\n",
      "W0714 00:36:06.478082 139779263436608 saved_model.py:765] Skipping full serialization of Keras layer <tensorflow.python.keras.saving.saved_model.Dense object at 0x7f1efb16b518>, because it is not built.\n",
      "W0714 00:36:06.479446 139779263436608 saved_model.py:765] Skipping full serialization of Keras layer <tensorflow.python.keras.saving.saved_model.Dense object at 0x7f1efb16b860>, because it is not built.\n",
      "W0714 00:36:06.481084 139779263436608 saved_model.py:765] Skipping full serialization of Keras layer <tensorflow.python.keras.saving.saved_model.Dense object at 0x7f1efb16bba8>, because it is not built.\n",
      "W0714 00:36:06.482719 139779263436608 saved_model.py:765] Skipping full serialization of Keras layer <tensorflow.python.keras.saving.saved_model.Dense object at 0x7f1efb16bef0>, because it is not built.\n",
      "W0714 00:36:06.484060 139779263436608 saved_model.py:765] Skipping full serialization of Keras layer <tensorflow.python.keras.saving.saved_model.Concatenate object at 0x7f1efb16bf98>, because it is not built.\n",
      "W0714 00:36:06.486252 139779263436608 saved_model.py:765] Skipping full serialization of Keras layer <tensorflow.python.keras.saving.saved_model.Reshape object at 0x7f1efb1711d0>, because it is not built.\n"
     ]
    }
   ],
   "source": [
    "# Define a model that do image preprocessing before inference.\n",
    "class CaptchaSolverInferenceModel(tf.keras.Model):\n",
    "  \n",
    "  def __init__(self, captchanet_model, **kwargs):\n",
    "    super().__init__(**kwargs)\n",
    "    self.captchanet_model = captchanet_model\n",
    "\n",
    "  @tf.function(input_signature=[tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.uint8)])\n",
    "  def solve(self, images):\n",
    "    images = tf.cast(images, tf.float32)\n",
    "    # Normalize images\n",
    "    images = tf.image.per_image_standardization(images)\n",
    "    images = tf.image.resize(images, (224, 224))\n",
    "    \n",
    "    # Inference\n",
    "    labels = self.captchanet_model(images)\n",
    "    labels = tf.argmax(labels, axis=2)\n",
    "    \n",
    "    # Freeze the tokenizer\n",
    "    n_letter = max(tokenizer.index_word.keys()) + 1\n",
    "    index = [''] * n_letter\n",
    "    for k, v in tokenizer.index_word.items():\n",
    "      index[k] = v\n",
    "    index = tf.constant(index, dtype=tf.string)\n",
    "        \n",
    "    # Decode labels\n",
    "    decoder = lambda x: tf.gather_nd(index, tf.expand_dims(x, axis=-1))\n",
    "    words = tf.map_fn(decoder, labels, dtype=tf.string)\n",
    "    joiner = lambda x: tf.strings.reduce_join(x, axis=0)\n",
    "    words = tf.map_fn(joiner, words, dtype=tf.string)\n",
    "\n",
    "    return words\n",
    "\n",
    "  \n",
    "inference_model = CaptchaSolverInferenceModel(model)\n",
    "inference_model_path = model_path / 'inference_model'\n",
    "tf.saved_model.save(inference_model, str(inference_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hadim/.data/Neural_Network/captchanet/model/v6.zip'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pack and zip the model directory\n",
    "import shutil\n",
    "archive_path = model_dir / model_path.stem\n",
    "shutil.rmtree(model_path / '.ipynb_checkpoints', ignore_errors=True)\n",
    "shutil.make_archive(archive_path, 'zip', root_dir=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument:  2 root error(s) found.\n  (0) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\n  (1) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\n0 successful operations.\n0 derived errors ignored.\n\t [[{{node StatefulPartitionedCall/map/while/body/_567/TensorArrayV2Write/TensorListSetItem/_58}}]]\n  (1) Invalid argument:  2 root error(s) found.\n  (0) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\n  (1) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\n0 successful operations.\n0 derived errors ignored.\n\t [[{{node StatefulPartitionedCall/map/while/body/_567/TensorArrayV2Write/TensorListSetItem/_58}}]]\n\t [[Func/StatefulPartitionedCall/map_1/while/body/_608/input/_967/_72]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_restored_function_body_66098]\n\nFunction call stack:\nrestored_function_body -> restored_function_body\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-424741230162>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Solve captcha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mpredicted_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mpredicted_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    432\u001b[0m               *args, **kwds)\n\u001b[1;32m    433\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    587\u001b[0m     \"\"\"\n\u001b[1;32m    588\u001b[0m     return self._call_flat(\n\u001b[0;32m--> 589\u001b[0;31m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0m\u001b[1;32m    590\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m    591\u001b[0m                            resource_variable_ops.ResourceVariable))))\n",
      "\u001b[0;32m~/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    443\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    444\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 445\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    446\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/captchanet/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/captchanet/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  2 root error(s) found.\n  (0) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\n  (1) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\n0 successful operations.\n0 derived errors ignored.\n\t [[{{node StatefulPartitionedCall/map/while/body/_567/TensorArrayV2Write/TensorListSetItem/_58}}]]\n  (1) Invalid argument:  2 root error(s) found.\n  (0) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\n  (1) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\n0 successful operations.\n0 derived errors ignored.\n\t [[{{node StatefulPartitionedCall/map/while/body/_567/TensorArrayV2Write/TensorListSetItem/_58}}]]\n\t [[Func/StatefulPartitionedCall/map_1/while/body/_608/input/_967/_72]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_restored_function_body_66098]\n\nFunction call stack:\nrestored_function_body -> restored_function_body\n"
     ]
    }
   ],
   "source": [
    "# Test the exported model\n",
    "\n",
    "inference_model = tf.saved_model.load(str(model_path / 'inference_model'))\n",
    "\n",
    "model_image_size = (224, 224)\n",
    "n  = 8\n",
    "fnames = [str(p) for p in val_data_dir.glob(\"*.tfrecord\")]\n",
    "dataset = tf.data.TFRecordDataset(fnames)\n",
    "dataset = dataset.map(map_func=captchanet.decode_data(tokenizer, image_size=model_image_size, max_len_word=10, input_as_dict=True))\n",
    "dataset = dataset.shuffle(1024)\n",
    "dataset = dataset.batch(n)\n",
    "data = [d for d in dataset.take(1)][0]\n",
    "\n",
    "images = data['original_image']\n",
    "labels = data['label']\n",
    "labels = tf.argmax(labels, axis=2)\n",
    "\n",
    "# Solve captcha\n",
    "predicted_words = inference_model.solve(images)\n",
    "predicted_words = predicted_words.numpy()\n",
    "\n",
    "# Plot\n",
    "original_images = data['original_image'].numpy()\n",
    "words = data['word'].numpy()\n",
    "words = [w.decode('utf-8').replace('0', '') for w in words]\n",
    "\n",
    "size = 2\n",
    "ncols = 2\n",
    "nrows = n // ncols\n",
    "ratio = original_images.shape[2] / original_images.shape[1]\n",
    "figsize = (ncols * size * ratio, size * nrows)\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize, constrained_layout=True)\n",
    "axs = axs.flatten()\n",
    "\n",
    "for image, word, predicted_word, ax in zip(images, words, predicted_words, axs):\n",
    "  ax.imshow(image)\n",
    "  \n",
    "  predicted_word = predicted_word.decode()\n",
    "  mark = 'OK' if predicted_word == word else 'WRONG'\n",
    "  text = f'True: {word} ({len(word)})'\n",
    "  text += f' - Predicted: {predicted_word} ({len(predicted_word)})'\n",
    "  text += f\" - {mark}\"\n",
    "  ax.set_title(text, fontsize=14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:captchanet]",
   "language": "python",
   "name": "conda-env-captchanet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
